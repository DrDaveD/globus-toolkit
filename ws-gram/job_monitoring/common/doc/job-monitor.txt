The JobMonitor (why doesn't stu want to call this RIPS2?) component will
demultiplex job state changes from the eventd implementations based on the
message id <-> job id associate table it has.  It runs with permissions of the
globus daemon account, within the Java hosting environment.

It will interact with
1. eventd - produces job state changes keyed on Job IDs
2. Managed Job service/resources
   a. Registers Message ID <-> Job ID mappings
   b. consumes job state changes keyed on Message IDs
3. Publishes job queue information(?)

Interaction #1
   The eventd component runs with permissions needed to access the scheduler-
   specific information. It's job is to obtain notifications of job state
   changes from the scheduler and forward those to JobMonitor. The
   notifications are implemented in various scheduler dependent ways (log file
   polling, signals, etc).

   The JobMonitor is a piece of Java code which will act as the parent process
   of the eventd. It will communicate with the eventd via the standard input
   and output streams of the Process. The reason for this is two-fold:
   - This allows the JobMonitor/eventd interaction to be done is a reasonably
     secure way---only those processes have convenient access to those file
     descriptors.
   - either the JobMonitor and the eventd can detect when the other has
     terminated by seeing end-of-file on their end of the stdin or stdout
     fd.

   When (re)starting the eventd, the Job Monitor will indicate the timestamp
   from which the eventd should begin reading events (if it has some
   persistent way to replay events).

   Communication will generally flow from the eventd to the Job Monitor.
   We may decide we need some sort of control info in the other direction
   to make clean safe shutdowns.

   All of the notifications from eventd to JobMonitor will consist of
       - job id
         scheduler-specific job identifier
       - timestamp
         time indicating when the state change occurred.
       - state
         new job state (one of PENDING, ACTIVE, DONE, FAILED, SUSPENDED?)
       - error reason [if new job state is FAILED]
         error string/integer relating to why the job failed 
             if known---probably only knowable in the exec() failed
             or scheduler killed the job
       - exit code(s) [if new job state is DONE]
         list integer exit codes for subprocesses if the job is DONE

   If the Job Monitor knows a mapping of the Job ID to a Message ID (and hence
   Managed Job Resource), it will promptly notify the resource (or
   service?---terminology) of the state change. (See interaction 2b)

   Otherwise, it will store it in a soft-state expiry queue, so that the
   state change can be propogated if a relevant mapping becomes available
   in the next X minutes. After X minutes, the state change will be removed
   from the queue.

Interaction #2a
    The JobMon component is visible to the Job Management service so that
    it may register for job state changes. The registration mechanism is
    done through Java method invocation.

    Registration will take as input a Message ID and a Job ID. Exception
    will be thrown if something is broken. New registrations will cause
    a thread in the Job Monitor to scan through the soft-state data and push
    these state changes to the Managed Job Resource using standard 2b
    interactions---these will be then removed from the soft-state cache.
   
Interaction #2b
    When the Job Monitor decides it has a state change to send to a particular
    Managed Job Resource, it will send this notification via a Java method
    on the Managed Job Service (port type method?) indicating the state
    change. It is up to the Managed Job Service to deliver it to the
    appropriate Managed Job Resource.

    Once the notification is completed, if the timestamp of the notification
    is older than that of any remaining in the soft state, then the restart
    point timestamp of the job monitor will be updated in persistent state.

Questions:
In writing the text for #2b, it seems to me (based on a superficial
understanding of wsrf) that the routing bit belongs in the Managed Job Service
so that there's not an extra piece of redirection needed to get the state
change to the appropriate resource object. Does this belong as a separate
piece?

How will we acquire the scheduler/queue information for publishing? How
often would we want to update it?
