Managed Job Scheduler Adapter Design
$Id$

Abstract

This document describes the design of the Scheduler Adapter-related
parts of the Managed Job Service. Specifically, it includes description of the
software components, their programming interfaces, and interactions. Also,
description of scheduler-specific considerations are discussed.

Motivation

This redesign of the managed job monitoring infrastructures is motivated by
the desire for improved performance (both responsiveness and scalability) in
the mechanisms the Managed Job service uses to receive job state
notifications.  These notifications are used to track the progress of
program execution jobs started by the Managed Job service. The GT3
implementations of these concepts rely on computational expensive queue-query
operations, SOAP-level inter-process communications, and in-memory state
management of current execution job states for all scheduler-managed jobs
(even those which were not managed by a Managed Job Service instance).

Component Overview

Scheduler Event Generator

The Scheduler Event Generator (SEG) is a program which uses
scheduler-specific monitoring modules to generate job state
change events. At the SEG level, the state change events correspond to 
changes in any jobs which are managed by the scheduler, even if they do
not correspond to jobs initiated by the Managed Job Service. These state
change events are propagated to the Job State Monitor.

Depending on scheduler-specific requirements, the SEG may need to run with 
priviledges to enable it to obtain scheduler event
notifications. As such, one SEG runs per scheduler resource. For example,
on a host which provides access to both PBS and fork jobs, two SEGs, running
at (potentially) different privilege levels will be running.

When executed, the SEG is able to start issuing events from some
time in the past. The SEG will, in general, not require any persistent
state between invocations. One SEG instance exists for any particular
scheduled resource instance (one for all homogeneous PBS queues, one for
all fork jobs, etc).

The SEG is implemented in an executable called the
globus-scheduler-event-generator, located in the Globus Toolkit's libexec
directory. It is invoked with the following command line:

    globus-scheduler-event-generator -s <SCHEDULER NAME> [-t <TIMESTAMP>]

It produces events in the format described in the SEG
Protocol section of this docment on the standard output of the process.

When begun, it loads the scheduler module named on the command line and
then defers to it for most functionality. When it detects an error writing
to stdout or reading stdin, it terminates. The scheduler specific
code uses the SEG API (described below) to emit events to the JSM.

Job State Monitor

The Job State Monitor (JSM) is a scheduler-independent object which provides
an interface between the process monitoring of the SEG and the Managed Job
Resources (MJR) which contain the state of a job created by the Managed Job
Service (MJS).

The JSM will contain a registry mapping scheduler-specific
job identifiers to MJR keys. When the SEG generates a job state change
event, the JSM will use it's registry to locate the MJR key corresponding
to the job and dispatch the state change to the MJS with the resource
context set to the contain the corresponding MJR key.

The JSM contains a soft-state cache of SEG events which aren't associated
with MJR keys in the registry (described above). Events in this cache are
replay if and when the MJS creates an association between a local Job
ID and a MJR. Events which aren't used for some configured interval are
automatically discarded by the JSM.

The basic JSM will have 1 persistent datum: the timestamp of the oldest
SEG event in the soft state cache. This datum will be used when the
JSM is restarted to get the SEG to replay the appropriate state.

Interactions and Protocols

Starting and Stopping the SEG

The JSM will be responsible for starting the SEG. As the JSM is implemented
in Java, it will use one of the Runtime.exec methods to start the SEG process.
The SEG command line is configured in the deployment properties which
are used by the MJFS to instantiate the MJR. The JSM will monitor the
execution of the SEG by having a thread always blocked reading the standard
output of the SEG. This output will contain the SEG events using the protocol
described below. When the JSM detects that the SEG has terminated prematurely,
it restarts the SEG.

The SEG monitors its standard input for a control messages. If the input
is closed by the parent process, the SEG self-termintes. If writing output
fails with an EPIPE error, then the SEG self-terminates, If other internal
problems occur, then the SEG may self-terminate and the JSM will restart
it.

SEG Protocol

The general form for the SEG protocol messages is

MESSAGE-TYPE;TIMESTAMP;message-type-specific content

MESSAGE-TYPE is a three-digit integer. The JSM will parse the message
contents based on the message type.

TIMESTAMP is an unsigned value indicating seconds since the UNIX epoch.

Message Types
    001 - Job State Change
        Message Format: 001;TIMESTAMP;JOBID;STATE;EXIT_CODE
        Message Type Specific Content:

        JOBID
            local scheduler-specific job id
        STATE
            new job state (integer as per the GRAM protocol constants)
        EXIT_CODE
            job exit code if STATE is done or failed.

OTHERS TBD

Programming Interfaces

JobStateMonitor

/**
 * Implementation of the JobStateMonitor.
 * 
 * This class starts a SEG at construction time and receives state
 * change notifications from the SEG. These are communicated to the
 * JobStateMonitorListener which is associated with the JobStateMonitor
 * when a mapping between the state change's local job ID and a resourceKey
 * exists.
 *
 * Question:
 * How should this implement it's one persistent property
 * (timestamp)?
 * Do I need to be more explicit about thread synchronizaiton in this
 * decsription?
 * Is the seg executable name passing a good way to start things up?
 */
public class JobStateMonitor {
    /**
     * Construct a new JobStateMonitor and begin the underlying SEG process.
     *
     * @param segPath
     *     Path to the SEG executable.
     * @param userId
     *     User ID that the SEG should run as (via sudo(1))
     * @param schedulerName
     *     Name of the scheduler this JobStateMonitor is expecting
     *     notifications about. 
     * @param listener
     *     Reference to the JobMonitorListener which will be notified
     *     when notifications relating to Job ID which has a mapping
     *     registered to it.
     *
     * @throws java.io.IOException
     *     Error starting the SEG process.
     */
    public void JobStateMonitor(java.io.File segPath,
                                String userId,
                                String schedulerName,
                                JobStateMonitorListener listener)
            throws java.io.IOException;

    /**
     * Register a mapping from local scheduler job ID to a resource key.
     * Once this method has been called for a particular local job
     * identifier, the JobStateMonitorListener associated with the
     * JobStatemonitor may receive notifications until the unregisterJobIDMap
     * method has been called.
     *
     * @param localId
     *     Local job identifier. This is presumably generated by the 
     *     scheduler when the job is created.
     * @param resourceKey
     *     Resource key associated with the job. This object will be
     *     passed to the JobStateMonitorListener's jobStateChange method.
     */
    public void registerJobIDMap(String localId, Object resourceKey)
        throws AlreadyRegisteredException;

    /**
     * Unregister a local scheduler job ID for event propagation.
     * Once this method has been called for a particular local job
     * identifier, the JobStateMonitorListener associated with the
     * JobStatemonitor will no longer receive notifications about this job.
     *
     * @param localId
     *     Local job identifier.
     */
    public void unregisterJobIDMap(String localId)
        throws NotRegisteredException;
}

/**
 * Job State Change notification listener.
 *
 * The Managed Job Service implements this interface to receive job
 * state change notifications which are related to a particular Managed Job
 * Resource.
 */
public interface JobStateMonitorListener {
    /**
     * Method called by the JobStateMonitor when a job changes state.
     *
     * @param resourceKey
     *     Resource key associated with the job that changed state.
     * @param timestamp
     *     Time when the job state change occurred.
     * @param state
     *     New job state.
     * @param exitCode
     *     Integer code inidicating the job exit condition (if the state value
     *     is the done or failed job state.
     */
    public void jobStateChange(Object resourceKey, java.util.Date timestamp,
            int state, int exitCode);
}

SEG API

/**
 * Format and send an arbitrary event message to the JobSchedulerMonitor
 * implementation. This is used to implement the rest of the event signalling
 * API.
 *
 * @param format
 *     Format string using the same format as described in the printf
 *     manual page.
 * @param ...
 *     Varargs values used for type conversions in the format string.
 * @retval 0
 *    Message sent.
 */
int
globus_scheduler_event(
    const char * format,
    ...);

/**
 * Send a job pending event to the JobSchedulerMonitor implementation.
 *
 * @param timestamp
 *        Timestamp to use for the event. If set to 0, the time which
 *        this function was called is used.
 * @param jobid
 *        String indicating the scheduler-specific name of the job.
 * @retval 0
 *    Message sent.
 */
int
globus_scheduler_event_pending(
    time_t                              timestamp,
    const char *                        jobid);


/**
 * Send a job active event to the JobSchedulerMonitor implementation.
 *
 * @param timestamp
 *        Timestamp to use for the event. If set to 0, the time which
 *        this function was called is used.
 * @param jobid
 *        String indicating the scheduler-specific name of the job.
 * @retval 0
 *    Message sent.
 */
int
globus_scheduler_event_active(
    time_t                              timestamp,
    const char *                        jobid);

/**
 * Send a job failed event to the JobSchedulerMonitor implementation.
 *
 * @param timestamp
 *        Timestamp to use for the event. If set to 0, the time which
 *        this function was called is used.
 * @param jobid
 *        String indicating the scheduler-specific name of the job.
 * @param failure_code
 *        Failure code of the process if known.
 * @retval 0
 *    Message sent.
 */
int
globus_scheduler_event_failed(
    time_t                              timestamp,
    const char *                        jobid,
    int                                 failure_code);

/**
 * Send a job done event to the JobSchedulerMonitor implementation.
 *
 * @param timestamp
 *        Timestamp to use for the event. If set to 0, the time which
 *        this function was called is used.
 * @param jobid
 *        String indicating the scheduler-specific name of the job.
 * @param exit_code
 *        Exit code of the process if known.
 * @retval 0
 *    Message sent.
 */
int
globus_scheduler_event_done(
    time_t                              timestamp,
    const char *                        jobid,
    int                                 exit_code);


SEG Modules

In addition to using the SEG API described above, Scheduler-specific SEG
modules must provide a pointer to their module descriptor as a global
variable called "globus_scheduler_event_module_ptr". This descriptor will be
activated when the SEG begins execution and deactivated when the SEG detects
its termination condition.

Scheduler-Specific Considerations

For most schedulers, the best way we have to deal with scheduler events is to
parse the scheduler-specific log file to get information about when jobs state
change.  Discussion of log file configuration information is included in the
scheduler-specific discussions below.

PBS

The following paragraph is from the OpenPBS Administrator Guide:
The amount of output in the logs depends on the selected events to log and the
presence of debug writes, turned on by compiling with -DDEBUG. The Server and
Mom can be directed to record only messages pertaining to certain event types.
The specified events are logically or-ed  . Their decimal values are:
1 Error Events
2 Batch System/Server Events
4 Administration Events
8 Job Events
16 Job Resource Usage (hex value 0x10)
32 Security Violations (hex value 0x20)
64 Scheduler Calls (hex value 0x40)
128 Debug Messages (hex value 0x80)
256 Extra Debug Messages (hex value 0x100)

For our purposes, PBS Server log must be configured to include both log level
2 and 8 events.

Level 2 provides information about when the log file is opened and closed, and
when the pbs server daemon is started and stopped.  These will make it easier
for the SEG to deal with log file rotation.

Level 8 provides information about when the jobs are begun, terminate, and are
cancelled. This information is translated into SEG events.

PBS log format appears to be
timestamp;log level?;originating daemon;log level string;jobid;message
Mapping to job state changes:
    PENDING: Job Queued at request of <daemon>
    <stop being suspended>: Holds <u|o|s> released at request of <daemon>
    <something else>: Job Modified at request of <something>
    ACTIVE: Job Run at request of <daemon>
    DONE: Exit_status=1
    cancelled: Job deleted at request of <user>

For log level string, the interesting values are:
Svr or Log (for level 2 messages)
Job (for level 8 messages)

Logs are named by date. Usually, the server log is located in 
PBS_HOME/server_logs/<date>

timestamp is in the format MM/DD/YYYY HH:MM:SS

LSF
The LSF log format is defined in the lsb.events(5) manual page. The current
log file is called lsb.events. As logs are rotated out, they are renamed
to names with an integer value appended. For example, the current log file
is called lsb.events; the previous logs are called lsb.events.1 through
lsb.events.99.

Log file rotation is governed by the MAX_JOB_NUM configuration parameter.

For the current event file, the first line contains the offset of the first
event which isn't also in the previous event file. In other files, the first
line is a timestamp of when the last event in that file occurs.

The log events in the log file are defined in lsb.events(5) manual page.

Another log file lsb.acct(5) contains information about job termination only.
Looks easier to parse, but doesn't have all the info we want.

LSB Log messages  we'll map to job state changes:
JOB_NEW for PENDING job state
JOB_EXCEPT for some failed cases:
exceptMask:
              0x01: missched
              0x02: overrun
              0x04: underrun
              0x08: abend
              0x10: cantrun
              0x20: hostfail
              0x40: startfail

JOB_STATUS for job state changes. The jStatus values are selected from these
lsf constants:

/* lsb job states */
#define JOB_STAT_NULL         0x00
#define JOB_STAT_PEND         0x01
#define JOB_STAT_PSUSP        0x02
#define JOB_STAT_RUN          0x04
#define JOB_STAT_SSUSP        0x08
#define JOB_STAT_USUSP        0x10
#define JOB_STAT_EXIT         0x20
#define JOB_STAT_DONE         0x40
#define JOB_STAT_PDONE        (0x80)  /* Post job process done successfully */
#define JOB_STAT_PERR         (0x100) /* Post job process has error */
#define JOB_STAT_WAIT         (0x200) /* Chunk job waiting its turn to exec */
#define JOB_STAT_UNKWN        0x10000

Q: Do we want to have a SUSPENDED job state (state loops ugh)

Condor
Condor logs jobs on a per submission configuration level. We can control
whether we want condor clusters to be in separate logs or in one large log.

Log file format is either xml (classads) or text. Probably we should opt for
text mode for easier/quicker parsing.

Log entries begin with 3 digit event type. They end with a line consisting
of "...". within parentheses after the event type is the job id
(cluster.process.000 -- to clarify terminology the cluster is the globus
concept of the job id. for a job with count > 1, the "process" will be in
the range of [0, count-1].

000 - submitted
001 - job executing
002 - job not executable
004 - job evicted (suspended?)
005 - terminated
006 - image size updated???
009 - aborted by user

(Don't know what others there are)

Fork
This is the trickier case. If we want to have this to work with job completion
signals for a responsive for system, we'll need to have a process which is a
fork job starter, which will execute all fork jobs (as the parent process) and
will receive a signal or wait() to receive notifications for when the
jobs terminate.

From that point, we need to pass the job state changes to the JSM. Two options
I am considering:
- Have the SEG and the fork job starter be the same process (stick the startup
  code into the fork SEG module). This allows for simpler communication
  between the SEG and the job starter, but requires that the fork starter read
  job submisison requests from either the file system or the standard input of
  the process, and requires that the SEG communicate job submission
  results to the Managed Job Service somehow (again, either filesystem or
  stdout and the obvious choices).
- Have the SEG and the fork job starter be separate processes. Communicate job
  state changes to the SEG via a log file. The SEG I/O stream is unmodified
  for fork specific trickery. If the SEG dies, the fork job starter won't, so
  it can continue to generate log events. the SEG can recover from crashes by
  scanning the log file for last handled timestamp.

I'm leaning towards the second notion. The only concern is that if the starter
crashes, we lose the ability to query those jobs. If we can detect that it
crashed, and know which pids it was monitoring, we could use the kill w/signal
0 trick to determine if those jobs are still running. (Do we need this level
of reliability for the first cut?)

Testing
- JSM
  Test that some resource can register ID to Object mappings
  Test that artifically generated events are propagated to the listener with
  the appropriate resource key
  Test that registration after events are generated causes replay of events in
  the soft-state cache.
  Test that the JSM recovers its persistent datum upon restart.

- SEG
  Test that SEG loads the appropriate module when started
  Test that the SEG passes the replay timestamp to the module appropriately
  Test that when SEG API calls are made, an appropriate message is emitted on
  the standard output of the SEG.
  Test that the SEG handles IO exceptions on stdin and stdout

- SEG modules
  Generate fake log files appropriate for the SEG module, test that parsing
  makes reasonable events out of them (consumer knows what the events should
  be).

- Integration
  Configure MJS w/JSM and run jobs which succeed/fail in various ways to 
  determine that the events are correct.
  Check that the timestamps on completion events are reasonable for sleep jobs
  (ie. it doesn't exit before the job could possibly terminate).

Potential Contingency Plans (in a pinch)
If the WSRF MJS is not suitable for release, we could make the JSM act
as a GT3-style JobMonitor implementation (maybe that's a good testing case if
WSRF MJS is incomplete when want need to test w/live data).

If the SEG modules are taking too long to implement, Make a scheduler neutral
one which acts like RIPS.
